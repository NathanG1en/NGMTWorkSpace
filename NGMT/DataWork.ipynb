{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# <div align=\"center\">                                                          \n",
    "# Inserting H5 File\n"
   ],
   "id": "4bd7f27cf407e104"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Imports",
   "id": "d8f353192497f631"
  },
  {
   "cell_type": "code",
   "id": "6cb70793",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T21:51:38.785575Z",
     "start_time": "2024-08-01T21:51:33.027152Z"
    }
   },
   "source": "!pip install h5py ",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: h5py in c:\\programdata\\anaconda3\\lib\\site-packages (3.11.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from h5py) (1.26.4)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T01:05:58.056312Z",
     "start_time": "2024-08-02T01:05:58.046652Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import actipy\n",
    "import h5py\n",
    "import numpy as np\n",
    "from kielmat.utils.kielmat_dataclass import KielMATRecording\n",
    "from kielmat.utils.file_io import get_unit_from_type\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ],
   "id": "e9ca330a5e8f0e09",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Editing our data\n",
   "id": "a600a92cc5f70561"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T23:53:46.989801Z",
     "start_time": "2024-08-01T23:53:46.985996Z"
    }
   },
   "cell_type": "code",
   "source": "file_path = '20220218-131956-P_009_TM_16.h5' #INSERT THE FILE HERE",
   "id": "57463bb00598627e",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T23:53:50.097314Z",
     "start_time": "2024-08-01T23:53:50.076737Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def list_attributes(file_path): # These functions will check current attributes and add the needed ones\n",
    "    \"\"\"List and print the attributes of the root group in an HDF5 file.\"\"\"\n",
    "    with h5py.File(file_path, 'r') as file:\n",
    "        root_attributes = list(file.attrs.keys())\n",
    "        print(\"Attributes of the root group:\")\n",
    "        for attr in root_attributes:\n",
    "            value = file.attrs[attr]\n",
    "            if isinstance(value, bytes):\n",
    "                value = value.decode('utf-8')  # Decode if value is bytes\n",
    "            print(f\"{attr}: {value}\")\n",
    "\n",
    "def add_or_edit_attribute(file_path, attribute_name, attribute_value):\n",
    "    \"\"\"Add or edit an attribute in the root group of an HDF5 file.\"\"\"\n",
    "    with h5py.File(file_path, 'a') as file:\n",
    "        file.attrs[attribute_name] = attribute_value\n",
    "        print(f\"Added/Updated attribute '{attribute_name}' with value: {attribute_value}\")\n",
    "\n",
    "def main():\n",
    "    # Define the file path\n",
    "    file_path = '20220218-131956-P_009_TM_16.h5'\n",
    "\n",
    "    # List existing attributes\n",
    "    print(\"Initial attributes:\")\n",
    "    list_attributes(file_path)\n",
    "\n",
    "    # Define new attribute values\n",
    "    case_id_list = [\"Subject 1\", \"Experiment Name\"]\n",
    "    monitor_label_list = [\n",
    "        'Accelerometer_X', 'Accelerometer_Y', 'Accelerometer_Z',\n",
    "        'Gyroscope_X', 'Gyroscope_Y', 'Gyroscope_Z',\n",
    "        'Magnetometer_X', 'Magnetometer_Y', 'Magnetometer_Z',\n",
    "        'Temperature'\n",
    "    ]\n",
    "\n",
    "    # Add or edit attributes\n",
    "    add_or_edit_attribute(file_path, 'CaseIdList', case_id_list)\n",
    "    add_or_edit_attribute(file_path, 'MonitorLabelList', monitor_label_list)\n",
    "\n",
    "    # Verify changes\n",
    "    print(\"\\nUpdated attributes:\")\n",
    "    list_attributes(file_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ],
   "id": "8ac6d5b1f701a788",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial attributes:\n",
      "Attributes of the root group:\n",
      "CaseIdList: ['Subject 1' 'Experiment Name']\n",
      "FileFormatVersion: 5\n",
      "MonitorLabelList: ['Accelerometer_X' 'Accelerometer_Y' 'Accelerometer_Z' 'Gyroscope_X'\n",
      " 'Gyroscope_Y' 'Gyroscope_Z' 'Magnetometer_X' 'Magnetometer_Y'\n",
      " 'Magnetometer_Z' 'Temperature']\n",
      "Added/Updated attribute 'CaseIdList' with value: ['Subject 1', 'Experiment Name']\n",
      "Added/Updated attribute 'MonitorLabelList' with value: ['Accelerometer_X', 'Accelerometer_Y', 'Accelerometer_Z', 'Gyroscope_X', 'Gyroscope_Y', 'Gyroscope_Z', 'Magnetometer_X', 'Magnetometer_Y', 'Magnetometer_Z', 'Temperature']\n",
      "\n",
      "Updated attributes:\n",
      "Attributes of the root group:\n",
      "CaseIdList: ['Subject 1' 'Experiment Name']\n",
      "FileFormatVersion: 5\n",
      "MonitorLabelList: ['Accelerometer_X' 'Accelerometer_Y' 'Accelerometer_Z' 'Gyroscope_X'\n",
      " 'Gyroscope_Y' 'Gyroscope_Z' 'Magnetometer_X' 'Magnetometer_Y'\n",
      " 'Magnetometer_Z' 'Temperature']\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Function from KielMAT\n",
   "id": "e8bc43dde3905360"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T00:26:33.492901Z",
     "start_time": "2024-08-02T00:26:33.478835Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def import_mobilityLab(file_name: str | Path, tracked_points: str | list[str]) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    if isinstance(file_name, str):\n",
    "        file_name = Path(file_name)\n",
    "\n",
    "    if isinstance(tracked_points, str):\n",
    "        tracked_points = [tracked_points]\n",
    "\n",
    "    try:\n",
    "        with h5py.File(file_name, \"r\") as hfile:\n",
    "            # Print available attributes for debugging\n",
    "            print(\"Available attributes:\")\n",
    "            for attr in hfile.attrs:\n",
    "                print(f\"{attr}: {hfile.attrs[attr]}\")\n",
    "            \n",
    "            # Get monitor labels and case IDs\n",
    "            monitor_labels = hfile.attrs.get(\"MonitorLabelList\", [])\n",
    "            case_ids = hfile.attrs.get(\"CaseIdList\", [])\n",
    "            \n",
    "            if not monitor_labels:\n",
    "                raise KeyError(\"MonitorLabelList attribute is missing or empty.\")\n",
    "            if not case_ids:\n",
    "                raise KeyError(\"CaseIdList attribute is missing or empty.\")\n",
    "            \n",
    "            # Convert arrays to lists if necessary\n",
    "            monitor_labels = monitor_labels.tolist() if isinstance(monitor_labels, np.ndarray) else monitor_labels\n",
    "            case_ids = case_ids.tolist() if isinstance(case_ids, np.ndarray) else case_ids\n",
    "\n",
    "            # Track invalid tracked points\n",
    "            invalid_tracked_points = [tp for tp in tracked_points if tp not in monitor_labels]\n",
    "\n",
    "            if invalid_tracked_points:\n",
    "                raise ValueError(f\"The following tracked points do not exist in monitor labels: {invalid_tracked_points}\")\n",
    "\n",
    "            # Initialize dictionaries to store channels and data frames\n",
    "            channels_dict = {\n",
    "                \"name\": [],\n",
    "                \"component\": [],\n",
    "                \"type\": [],\n",
    "                \"tracked_point\": [],\n",
    "                \"units\": [],\n",
    "                \"sampling_frequency\": [],\n",
    "            }\n",
    "\n",
    "            # Create dictionary to store data\n",
    "            data_dict = {}\n",
    "\n",
    "            # Iterate over each sensor\n",
    "            for idx_sensor, (monitor_label, case_id) in enumerate(zip(monitor_labels, case_ids)):\n",
    "                if monitor_label not in tracked_points:\n",
    "                    continue\n",
    "                \n",
    "                sample_rate = hfile[case_id].attrs.get(\"SampleRate\", None)\n",
    "                if sample_rate is None:\n",
    "                    raise KeyError(f\"SampleRate attribute is missing for case ID: {case_id}\")\n",
    "\n",
    "                # Get raw data\n",
    "                rawAcc = hfile[case_id][\"Calibrated\"][\"Accelerometers\"][:]\n",
    "                rawGyro = hfile[case_id][\"Calibrated\"][\"Gyroscopes\"][:]\n",
    "                rawMagn = hfile[case_id][\"Calibrated\"][\"Magnetometers\"][:]\n",
    "\n",
    "                # Populate data_dict\n",
    "                data_dict[f\"{monitor_label}\"] = pd.DataFrame({\n",
    "                    f\"{monitor_label}_ACCEL_x\": rawAcc[:, 0],\n",
    "                    f\"{monitor_label}_ACCEL_y\": rawAcc[:, 1],\n",
    "                    f\"{monitor_label}_ACCEL_z\": rawAcc[:, 2],\n",
    "                    f\"{monitor_label}_GYRO_x\": rawGyro[:, 0],\n",
    "                    f\"{monitor_label}_GYRO_y\": rawGyro[:, 1],\n",
    "                    f\"{monitor_label}_GYRO_z\": rawGyro[:, 2],\n",
    "                    f\"{monitor_label}_MAGN_x\": rawMagn[:, 0],\n",
    "                    f\"{monitor_label}_MAGN_y\": rawMagn[:, 1],\n",
    "                    f\"{monitor_label}_MAGN_z\": rawMagn[:, 2],\n",
    "                })\n",
    "\n",
    "                # Extend lists in channels_dict\n",
    "                channels_dict[\"name\"].extend([\n",
    "                    f\"{monitor_label}_ACCEL_x\",\n",
    "                    f\"{monitor_label}_ACCEL_y\",\n",
    "                    f\"{monitor_label}_ACCEL_z\",\n",
    "                    f\"{monitor_label}_GYRO_x\",\n",
    "                    f\"{monitor_label}_GYRO_y\",\n",
    "                    f\"{monitor_label}_GYRO_z\",\n",
    "                    f\"{monitor_label}_MAGN_x\",\n",
    "                    f\"{monitor_label}_MAGN_y\",\n",
    "                    f\"{monitor_label}_MAGN_z\",\n",
    "                ])\n",
    "\n",
    "                channels_dict[\"component\"].extend([\"x\", \"y\", \"z\"] * 3)\n",
    "                channels_dict[\"type\"].extend([\n",
    "                    \"ACCEL\", \"ACCEL\", \"ACCEL\",\n",
    "                    \"GYRO\", \"GYRO\", \"GYRO\",\n",
    "                    \"MAGN\", \"MAGN\", \"MAGN\"\n",
    "                ])\n",
    "                channels_dict[\"tracked_point\"].extend([monitor_label] * 9)\n",
    "                channels_dict[\"units\"].extend([\n",
    "                    \"m/s^2\", \"m/s^2\", \"m/s^2\",\n",
    "                    \"rad/s\", \"rad/s\", \"rad/s\",\n",
    "                    \"µT\", \"µT\", \"µT\"\n",
    "                ])\n",
    "                channels_dict[\"sampling_frequency\"].extend([sample_rate] * 9)\n",
    "\n",
    "    except KeyError as e:\n",
    "        print(f\"KeyError: {e}\")\n",
    "        return pd.DataFrame(), pd.DataFrame()\n",
    "    except ValueError as e:\n",
    "        print(f\"ValueError: {e}\")\n",
    "        return pd.DataFrame(), pd.DataFrame()\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "    # Concatenate data frames from data_dict\n",
    "    data = pd.concat(list(data_dict.values()), axis=1)\n",
    "\n",
    "    # Create DataFrame from channels_dict\n",
    "    channels = pd.DataFrame(channels_dict)\n",
    "\n",
    "    return data, channels\n"
   ],
   "id": "bcbdacdb5ce2325",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Importing Our Data\n",
   "id": "2a7b241076a868a7"
  },
  {
   "cell_type": "code",
   "id": "d03c7439",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T00:59:17.720179Z",
     "start_time": "2024-08-02T00:59:17.709023Z"
    }
   },
   "source": [
    "tracked_point = \"lowerBack\"\n",
    "data,channels = import_mobilityLab(file_path, tracked_point)\n",
    "data"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available attributes:\n",
      "CaseIdList: ['Subject 1' 'Experiment Name']\n",
      "FileFormatVersion: 5\n",
      "MonitorLabelList: ['Accelerometer_X' 'Accelerometer_Y' 'Accelerometer_Z' 'Gyroscope_X'\n",
      " 'Gyroscope_Y' 'Gyroscope_Z' 'Magnetometer_X' 'Magnetometer_Y'\n",
      " 'Magnetometer_Z' 'Temperature']\n",
      "ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T13:07:28.038286Z",
     "start_time": "2024-09-06T13:07:27.649998Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def read_and_clean_tsv(file_path, new_headers, skiprows=2):\n",
    "    \"\"\"\n",
    "    Reads a TSV file into a DataFrame, skips rows, and assigns new headers.\n",
    "\n",
    "    Parameters:\n",
    "        file_path (str): The path to the TSV file.\n",
    "        new_headers (list): A list of new column headers to assign.\n",
    "        skiprows (int): The number of rows to skip from the start of the file (default is 2).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The cleaned DataFrame.\n",
    "    \"\"\"\n",
    "    # Read the TSV file into a DataFrame with specified headers\n",
    "    df = pd.read_csv(file_path, sep='\\t', skiprows=skiprows, header=1)\n",
    "\n",
    "    # Assign the new headers to the DataFrame\n",
    "    df.columns = new_headers\n",
    "\n",
    "    return df\n",
    "\n",
    "# Example usage\n",
    "file_path = 'IMUS1.tsv'\n",
    "new_headers = [\n",
    "    'Time', 'Accelerometer_X', 'Accelerometer_Y', 'Accelerometer_Z',\n",
    "    'Gyroscope_X', 'Gyroscope_Y', 'Gyroscope_Z',\n",
    "    'Magnetometer_X', 'Magnetometer_Y', 'Magnetometer_Z',\n",
    "    'Barometer', 'Orientation_S', 'Orientation_X', 'Orientation_Y', 'Orientation_Z'\n",
    "]\n",
    "\n",
    "df = read_and_clean_tsv(file_path, new_headers)\n",
    "\n",
    "# Display the shape and the first few rows of the DataFrame\n",
    "df.head(5)"
   ],
   "id": "91eefc4b2ec9e3c8",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 30\u001B[0m\n\u001B[0;32m     22\u001B[0m file_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mIMUS1.tsv\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m     23\u001B[0m new_headers \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m     24\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTime\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAccelerometer_X\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAccelerometer_Y\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAccelerometer_Z\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m     25\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mGyroscope_X\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mGyroscope_Y\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mGyroscope_Z\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m     26\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMagnetometer_X\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMagnetometer_Y\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMagnetometer_Z\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m     27\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mBarometer\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mOrientation_S\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mOrientation_X\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mOrientation_Y\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mOrientation_Z\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m     28\u001B[0m ]\n\u001B[1;32m---> 30\u001B[0m df \u001B[38;5;241m=\u001B[39m read_and_clean_tsv(file_path, new_headers)\n\u001B[0;32m     32\u001B[0m \u001B[38;5;66;03m# Display the shape and the first few rows of the DataFrame\u001B[39;00m\n\u001B[0;32m     33\u001B[0m df\u001B[38;5;241m.\u001B[39mhead(\u001B[38;5;241m5\u001B[39m)\n",
      "Cell \u001B[1;32mIn[1], line 14\u001B[0m, in \u001B[0;36mread_and_clean_tsv\u001B[1;34m(file_path, new_headers, skiprows)\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;124;03mReads a TSV file into a DataFrame, skips rows, and assigns new headers.\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;124;03m    pd.DataFrame: The cleaned DataFrame.\u001B[39;00m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;66;03m# Read the TSV file into a DataFrame with specified headers\u001B[39;00m\n\u001B[1;32m---> 14\u001B[0m df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(file_path, sep\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[38;5;124m'\u001B[39m, skiprows\u001B[38;5;241m=\u001B[39mskiprows, header\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     16\u001B[0m \u001B[38;5;66;03m# Assign the new headers to the DataFrame\u001B[39;00m\n\u001B[0;32m     17\u001B[0m df\u001B[38;5;241m.\u001B[39mcolumns \u001B[38;5;241m=\u001B[39m new_headers\n",
      "\u001B[1;31mNameError\u001B[0m: name 'pd' is not defined"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
